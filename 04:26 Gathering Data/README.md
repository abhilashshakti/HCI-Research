HOW TO DO EXPERIMENTS -- ⅘

It really was a fun chapter to read. The author does a great job in explaining the simple yet powerful ideas of defining variables in an experiment which are sometimes ignored. The language of this reading is easy to understand (making it a universal reading), cartoons in between ensure that the readers are engaged even when the topic gets a little repetitive and the end experiment (in author’s psychology class) perfectly encapsulated the crux of this paper. But, the thing that stood out for me was how smoothly the author makes a transition from one idea to another (eg: control variables to dependent variables). Also, not just the topics but also the examples are not discussed in isolation but well connected to give a sense of storytelling in the otherwise technical discussion on learning to do experiments. 

There were several instances when I could relate a topic in this chapter to something I have read before. Eg: The entire concept of doing experiments using dependent, independent, control and random variables can be presented through an “A/B Testing” use case in a web experiment. I wish the author had emphasized on this. Also, in the last class we had a discussion on strategy circumplex, with 3 criteria: generalizability, precision and realism. Author time and again talks about the loss of generalizability in controlled experiments, thus improving precision. I wish the author had made a reference to this circumplex, which would have enhanced reader’s understanding.

I want to elaborate more on the topic of randomization within blocks (under the heading randomization within constraints). I like to call this “nested randomization”. Since there are 2 independent variable (high intensity (H) and low intensity (L)), we can have 4 classes (LL, LH, HL, HH). Given a total of 12 trials, we should have 3 blocks (12/4 = 3). Each of these blocks will have all the 4 class, thus eliminating the effect of ordering of independent variables. As is the case with non-mathematical readings (like this), use of numbers and equations is minimal often leaving the readers perplexed about outcomes of distribution.

Apart from your thoughtful critique, please answer the following question: What is regression to the mean? Give an example. The author puts forward the axiom that when experimenters choose participants on the basis of their scoring (very high or very low) on a particular test, the scores tend to move towards the mean on a second test. This is mainly a result of the “error component” in the experiment. An example of this could be demonstrated through the paper on “parallel prototyping”. Although the paper did not present the exact scores the participants (designers) received from the experts after each prototype was made (for both serial and parallel prototypes), I guess their scores would have moved towards the mean. With every subsequent iteration, the participants would have improved and biases should have reduced due to the factors mentioned in the statistical regression section.

I want to add an observation on this topic, namely the “power of extremes”. The outliers (or extreme values) such as very low score and very high scores can overpower the scores of participants lying in between of the spectrum and impact the mean IQ score. Thus, mean is not a reliable observation when proposing the outcome that “the average IQ of the group increased by seven points”

